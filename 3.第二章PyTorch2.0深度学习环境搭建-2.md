![image](https://github.com/user-attachments/assets/0c3a362f-c889-48d0-bff4-445003f4c4db)

### 2.4 图像降噪：手把手实战第一个深度学习模型
2.3节的程序读者可能感觉过于简单，直接调用库，再调用模型及其方法，即可完成所需要的功能。然而真正的深度学习程序设计不会这么简单，为了给读者建立一个使用PyTorch进行深度学习的总体印象，在这里准备了一个实战案例，手把手地演示进行深度学习任务所需要的整体流程，读者在这里不需要熟悉程序设计和编写，只需要了解整体步骤和每个步骤所涉及的内容即可。

#### 2.4.1 MNIST数据集的准备
HelloWorld是任何一种编程语言入门的基础程序，任何一位初学者在开始编程学习时，打印的第一句话往往就是HelloWorld。在深度学习编程中也有其特有的“HelloWorld”，一般指的是采用MNIST完成一项特定的深度学习项目。

对于好奇的读者来说，一定有一个疑问，MNIST究竟是什么？

实际上，MNIST是一个手写数字图片的数据集，它有60,000个训练样本集和10,000个测试样本集。打开后，MNIST数据集如图2-24所示。

![image](https://github.com/user-attachments/assets/d8fe9dc5-0644-4176-ba54-d0d06c8b8514)


读者可直接使用本书配套源码中提供的MNIST数据集，保存在dataset文件夹中，如图2-25所示。

![image](https://github.com/user-attachments/assets/7d917270-f32d-4524-91f0-93ba4e9a66fc)


之后使用NumPy数据库进行数据读取，代码如下：
```python
import numpy as np
x_train = np.load("./dataset/mnist/x_train.npy")
y_train_label = np.load("./dataset/mnist/y_train_label.npy")
```
读者也可以在百度搜索MNIST，直接下载train-images-idx3-ubyte.gz、train-labels-idx1-ubyte.gz等4个文件，如图2-26所示。

![image](https://github.com/user-attachments/assets/2af2c1e4-8322-4647-9920-536836c8e3a0)


下载这4个文件并解压缩。解压缩后可以发现这些文件并不是标准的图像格式，而是二进制格式，包括一个训练图片集、一个训练标签集、一个测试图片集以及一个测试标签集。其中训练图片集的内容如图2-27所示。

![image](https://github.com/user-attachments/assets/0951a774-5b22-4f1f-8f1d-ac8f02e3eadc)


MNIST训练集内部的文件结构如图2-28所示。

![image](https://github.com/user-attachments/assets/e9b43a51-1be8-4ffc-bdbb-c2fc84d85cd2)


如图2-26所示是训练集的文件结构，其中有60,000个实例。也就是说这个文件包含60,000个标签内容，每个标签的值为一个0 - 9的数。这里我们先解析每个属性的含义。首先，该数据是以二进制格式存储的，我们读取的时候要以rb方式读取；其次，真正的数据只有[value]这一项，其他的[type]等只是用来描述的，并不真正在数据文件中。

也就是说，在读取真实数据之前，要读取4个32位整数。由[offset]可以看出，真正的像从0016开始，每个像素占用一个int 32位。因此，在读取像素之前，要读取4个32位整数，也就是magic number、number of images、number of rows和number of columns。

结合图2-26的文件结构和图2-25的原始二进制数据内容可以看到，图2-25起始的4字节数0000 0803对应图2-26中列表的第一行，类型是magic number（魔数），这个数字的作用为文件校验数，用来确认这个文件是不是MNIST里面的train-images-idx3-ubyte文件。而图2-25中的0000 ea60对应图2-26图列表的第二行，转化为十进制为60000，这是文件总的容量数。

下面依次对应。图2-25中从第8个字节开始有一个4字节数0000 001c十进制值为28，也就是表示每幅图片的行数。同样地，从第12个字节开始的0000 001c表示每幅图片的列数，值也为28。而从第16个字节开始则是依次每幅图片像素值的具体内容。

这里使用每784（28×28）字节代表一幅图片，如图2-29所示。

![image](https://github.com/user-attachments/assets/762ed461-c818-4f71-8a49-2ba760cbb666)


#### 2.4.2 MNIST数据集的特征和标签介绍
对于数据库的获取，前面介绍了两种不同的MNIST数据集的获取方式，本小节推荐使用本书配套源码包中的MNIST数据集进行数据的读取，代码如下：
```python
import numpy as np
x_train = np.load("./dataset/mnist/x_train.npy")
y_train_label = np.load("./dataset/mnist/y_train_label.npy")
```
这里numpy库函数会根据输入的地址对数据进行处理，并自动将其分解成训练集和验证集。打印训练集的维度如下：
```python
(60000, 28, 28)
(60000, )
```
这是进行数据处理的第一步，有兴趣的读者可以进一步完成数据的训练集和测试集的划分。

回到MNIST数据集，每个MNIST实例数据单元也是由两部分构成的，分别是一幅包含手写数字的图片和一个与其相对应的标签。可以将其中的标签特征设置成y，而图片特征矩阵以x来代替，所有的训练集和测试集中都包含x和y。

![image](https://github.com/user-attachments/assets/59ce3232-6df6-4e41-90e6-55f3776b8044)


图2-30用更为一般化的形式解释了MNIST数据实例的展开形式。在这里，图片数据被展开成矩阵的形式，矩阵的大小为28×28。至于如何处理这个矩阵，常用的方法是将其展开，而展开的方式和顺序并不重要，只需要将其按同样的方式展开即可。

下面回到对数据的读取，前面已经介绍了，MNIST数据集实际上就是一个包含着60,000幅图片的60,000×28×28大小的矩阵张量[60000,28,28]，如图2-31所示。

![image](https://github.com/user-attachments/assets/d4de6dab-6f20-4dca-8cb3-a63c781422f9)


矩阵中行数指的是图片的索引，用以对图片进行提取，而后面的28×28个向量用以对图片特征进行标注。实际上，这些特征向量就是图片中的像素点，每幅手写图片是[28,28]的大小，每个像素转化为一个0 - 1的浮点数，构成矩阵。

#### 2.4.3 模型的准备和介绍
对于使用PyTorch进行深度学习的项目来说，一个非常重要的内容是模型的设计，模型用于决定在深度学习项目中采用哪种方式完成目标的主体设计。在本例中，我们的目的是输入一幅图像之后对其进行去噪处理。

对于模型的选择，一个非常简单的思路是，图像输出的大小就应该是输入的大小，在这里选择使用Unet（一种卷积神经网络）作为设计的主要模型。

注意：对于模型的选择现在还不是读者需要考虑的问题，随着你对本书学习的深入，见识到更多处理问题的方法后，对模型的选择自然会心领神会。

我们可以整体看一下Unet的结构（读者目前只需要知道Unet的输入和输出大小是同样的维度即可），如图2-32所示。

![image](https://github.com/user-attachments/assets/69ba446b-3869-4098-a463-cb231c6457f9)


可以看到，对于整体模型架构来说，其通过若干模块（block）与直连（residual）进行数据处理。这部分内容在后面的章节会讲到，目前读者只需要知道模型有这种结构即可。Unet模型的整体代码如下：
```python
import torch
import einops.layers.torch as elt

class Unet(torch.nn.Module):
    def __init__(self):
        super(Unet, self).__init__()
        #模块化结构，这也是后面常用到的模型结构
        self.first_block_down = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
            torch.nn.GELU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.second_block_down = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            torch.nn.GELU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.latent_space_block = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            torch.nn.GELU()
        )
        self.second_block_up = torch.nn.Sequential(
            torch.nn.Upsample(scale_factor=2),
            torch.nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),
            torch.nn.GELU()
        )
        self.first_block_up = torch.nn.Sequential(
            torch.nn.Upsample(scale_factor=2),
            torch.nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1),
            torch.nn.GELU()
        )
        self.convUP_end = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, padding=1),
            torch.nn.Tanh()
        )

    def forward(self, img_tensor):
        image = img_tensor
        image = self.first_block_down(image)
        image = self.second_block_down(image)
        image = self.latent_space_block(image)
        image = self.second_block_up(image)
        image = self.first_block_up(image)
        image = self.convUP_end(image)
        return image

if __name__ == '__main__':
    image = torch.randn(size=(5,1,28,28))
    Unet()(image)
```
上面倒数第1 - 3行的代码段表示只有在本文件作为脚本直接执行时才会被执行，而在本文件import到其他脚本中（代码重用）时这段代码不会被执行。

#### 2.4.4 对目标的逼近——模型的损失函数与优化函数
除了深度学习模型外，要完成一个深度学习项目，另一个非常重要的内容是设定模型的损失函数与优化函数。初学者对这两部分内容可能不太熟悉，在这里只需要知道有这部分内容即可。

首先是对于损失函数的选择，在这里选用MSELoss作为损失函数，MSELoss函数的中文名字为均方损失函数。

MSELoss的作用是计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小，均方差函数常用于线性回归模型的计算。在PyTorch中，使用MSELoss的代码如下：
```python
loss = torch.nn.MSELoss(reduction="sum")(pred, y_batch)
```
下面是优化函数的设定，在这里采用Adam优化器。对于Adam优化函数，请读者自行查找资料学习，在这里只提供使用Adam优化器的代码，如下所示：
```python
optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)
```

#### 2.4.5 基于深度学习的模型训练
前面介绍了深度学习的数据准备、模型、损失函数以及优化函数，本小节使用PyTorch训练出一个可以实现去噪性能的深度学习整理模型，完整代码如下（代码文件参看本书配套代码）：
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  #指定GPU编码
import torch
import numpy as np
import unet
import matplotlib.pyplot as plt
from tqdm import tqdm

batch_size = 320  #设定每次训练的批次数
epochs = 1024  #设定训练次数
#device = "cpu"  #PyTorch的特性，需要指定计算的硬件，如果没有GPU的存在，就使用CPU进行计算
device = "cuda"  #在这里默认使用GPU模式，如果出现运行问题，可以将其改成CPU模式
model = unet.Unet()  #导入Unet模型
model = model.to(device)  #将计算模型传入GPU硬件等待计算
model = torch.compile(model)  #PyTorch 2.0的特性，加速计算速度
optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)  #设定优化函数
#载入数据
x_train = np.load("./dataset/mnist/x_train.npy")
y_train_label = np.load("./dataset/mnist/y_train_label.npy")
x_train_batch = []
for i in range(len(y_train_label)):
    if y_train_label[i] < 2:  #为了加速演示，这里只对数据集中小于2的数字，也就是0和1进行运行，读者可以自行增加训练个数
        x_train_batch.append(x_train[i])

x_train = np.reshape(x_train_batch, [-1, 1, 28, 28])  #修正数据输入维度: [(30596, 28, 28)]
x_train /= 512.
train_length = len(x_train) * 20  #增加数据的单词循环次数
for epoch in range(epochs):
    train_num = train_length // batch_size  #计算有多少批次
    train_loss = 0  #用于损失函数的统计
    for i in tqdm(range(train_num)):  #开始循环训练
        x_imgs_batch = []  #创建数据的临时存储位置
        x_step_batch = []
        y_batch = []
        # 对每个批次内的数据进行处理
        for b in range(batch_size):
            img = x_train[np.random.randint(x_train.shape[0])]  #提取单幅图片内容
            x = img
            y = img
            x_imgs_batch.append(x)
            y_batch.append(y)
        #将批次数据转化为PyTorch对应的tensor格式并将其传入GPU中
        x_imgs_batch = torch.tensor(x_imgs_batch).float().to(device)
        y_batch = torch.tensor(y_batch).float().to(device)
        pred = model(x_imgs_batch)  #对模型进行正向计算
        loss = torch.nn.MSELoss(reduction=True)(pred, y_batch)/batch_size  #使用损失函数进行计算

        #下面是固定格式，一般这样使用即可
        optimizer.zero_grad()  #对结果进行优化计算
        loss.backward()  #损失值的反向传播
        optimizer.step()  #对参数进行更新
        train_batch_loss += loss.item()  #记录每个批次的损失值

    train_loss /= train_num
    print('train_loss:', train_loss)
    #下面对数据进行打印
    image = x_train[np.random.randint(x_train.shape[0])]  #随机挑选一条数据进行计算
    image = np.reshape(image,[1,1,28,28])  #修正数据维度
    image = torch.tensor(image).float().to(device)  #将挑选的数据传入硬件中等待计算
    image = model(image)  #使用模型对数据进行计算
    image = torch.reshape(image,shape=[28,28])  #修正模型输出结果
    image = image.detach().cpu().numpy()  #将计算结果导入CPU中进行后续计算或者展示
    #展示或存储数据结果
    plt.imshow(image)
    plt.savefig(f"./img/img_{epoch}.jpg")
```
在这里展示了完整的模型训练过程，首先传入数据，然后使用模型对数据进行计算，计算结果与真实值的误差被回传到模型中，最后PyTorch框架根据回传的误差对整体模型参数进行修正。

训练流程如图2-33所示。

![image](https://github.com/user-attachments/assets/0cadb67b-f687-4b03-85b1-743b4b5e9d55)


从图2-33中可以很清楚地看到，随着训练的进行，模型逐渐学会对输入的数据进行整形和输出，此时从输出结果来看，模型已经能够很好地对输入的图形细节进行修正，读者可以自行运行代码测试一下。

### 2.5 本章小结
本章是PyTorch程序设计的开始，介绍了PyTorch程序设计环境与基本软件安装，并演示了第一个基于PyTorch的深度学习程序整体设计过程及其部分处理组件。实际上，深度学习的程序设计是由各种处理组件组装起来完成的，本书的后续章节就是针对各种处理组件进行深入讲解。 
