方法将这部分计算过程分开计算，从而获得参数上的数据量减少。

答案是可以的。深度可分离卷积总体如图5 - 14所示。

![image](https://github.com/user-attachments/assets/822347ec-482d-4c44-906d-242a39c0f180)



在进行深度卷积的时候，每个卷积核只关注单个通道的信息，而在分离卷积中，每个卷积核可以联合多个通道的信息。这在PyTorch 2.0中的具体实现如下：

```python
#group=3是依据通道数设置的分离卷积数
Conv2d(in_channels=3, out_channels=3, kernel_size=3, groups=3) #这是第一步完成跨通道计算
Conv2d(in_channels=3, out_channels=4, kernel_size=1) #完成平面内计算
```

可以看到，此时我们在传统的卷积层定义上额外增加了`groups=4`的定义，这是根据通道数对卷积类的定义进行划分。下面通过一个具体的例子说明常规卷积与深度可分离卷积的区别。

常规卷积操作如图5 - 15所示。

![image](https://github.com/user-attachments/assets/ede9ef7b-4a2a-4e0f-a325-5907cfed3c6d)


假设输入层为一个大小为\(28×28\)像素、三通道的彩色图片。经过一个包含4个卷积核的卷积层，卷积核尺寸为\(3×3×3\)。最终会输出具有4个通道数据的特征向量，而尺寸大小由卷积的Padding方式决定。

在深度可分离卷积操作中，深度卷积操作有以下两个步骤。

（1）分离卷积的独立计算，如图5 - 16所示。

![image](https://github.com/user-attachments/assets/fc017dd7-c44f-4fa4-94c9-89e4863da74e)



图5 - 16中深度卷积使用的是3个尺寸为\(3×3\)的卷积核，经过该操作之后，输出的特征图尺寸为\(28×28×3\)（padding = 1）。

（2）堆积多个可分离卷积计算，如图5 - 17所示（注意图5 - 17中输入的是图5 - 16第一步的输出）。


可以看到，图5 - 17中使用了4个独立的通道完成，经过此步骤后，由第一个步骤输入的特征图在4个独立的通道计算下，输出维度变为\(28×28×3\)。

![image](https://github.com/user-attachments/assets/a80eb31c-ce89-4977-b49b-173ca8387fe4)


#### 5.3.2 深度的定义以及不同计算层待训练参数的比较

前面介绍了深度可分离卷积，并在一开始的时候就提到了深度可分离卷积可以减少待训练参数，那么事实是否如此呢？我们通过代码打印待训练参数数量进行比较，代码如下：

```python
import torch
from torch.nn import Conv2d, Linear

linear = Linear(in_features=3*28*28, out_features=3*28*28)
linear_params = sum(p.numel() for p in linear.parameters() if p.requires_grad)

conv = Conv2d(in_channels=3, out_channels=3, kernel_size=3)
params = sum(p.numel() for p in conv.parameters() if p.requires_grad)

depth_conv = Conv2d(in_channels=3, out_channels=3, kernel_size=3, groups=3)
point_conv = Conv2d(in_channels=3, out_channels=3, kernel_size=1)

# 需要注意的是，这里是先进行深度，然后进行逐点卷积，从而两者结合，就得到了深度、可分离、卷积
depthwise_separable_conv = torch.nn.Sequential(depth_conv, point_conv)
params_depthwise = sum(p.numel() for p in depthwise_separable_conv.parameters() if p.requires_grad)

print(f"多层感知机使用的参数为 {params} parameters.")
print("---------------------")
print(f"普通卷积层使用的参数为 {params} parameters.")
print("---------------------")
print(f"深度可分离卷积使用的参数为 {params_depthwise} parameters.")
```
在上面的代码段中，作者依次准备了多层感知机、普通卷积层以及深度可分离卷积，对其输出待训练参数，结果如图5 - 18所示。

![image](https://github.com/user-attachments/assets/09227798-f007-478a-aea5-beb0ee62b105)


可以很明显地看到，图5 - 18中对参数的输出随着采用不同的计算层，待训练参数也会随之变化，即使一个普通的深度可分离卷积层也能减少一半的参数使用量。

#### 5.3.3 膨胀卷积详解
我们先回到PyTorch 2.0中对卷积的说明，此时读者应该了解了group参数的含义，这里还有一个不常用的参数dilation，这是决定卷积层在计算时的膨胀系数。dilation有点类似于stride，实际含义为：每个点之间有空隙的过滤器，即为dilation，如图5 - 19所示。

![image](https://github.com/user-attachments/assets/0096a2fa-296a-4feb-86ab-fc759dc5e761)



简单地说，膨胀卷积通过在卷积核中增加空洞，可以增加单位面积中计算的大小，从而扩大模型的计算视野。

卷积核的膨胀系数（空洞的大小）每一层是不同的，一般可以取（1, 2, 4, 8, …），即前一层的两倍。注意膨胀卷积的上下文大小和层数是指数相关的，可以通过比较少的卷积层得到更大的计算面积。使用膨胀卷积的方法如下：

```python
#注意这里dilation被设置为2
depth_conv = Conv2d(in_channels=3, out_channels=3, kernel_size=3, groups=3, dilation=2)
point_conv = Conv2d(in_channels=3, out_channels=3, kernel_size=1)

# 深度、可分离、膨胀卷积的定义
depthwise_separable_conv = torch.nn.Sequential(depth_conv, point_conv)
```
需要注意的是，在卷积层的定义中，只有dilation被设置成大于或等于2的整数时，才能实现膨胀卷积。
对于其参数大小的计算，读者可以自行完成。

#### 5.3.4 实战：基于深度可分离膨胀卷积的MNIST手写体识别

下面进入实战部分，基于前期介绍的深度可分离膨胀卷积完成实战的MNIST手写体的识别。

首先是模型的定义，在这里我们预期使用自定义的卷积替代部分原生卷积完成模型的设计，代码如下：

```python
import torch
import torch.nn as nn
import numpy as np
import einops.layers.torch as elt

#下面是自定义的深度、可分离、膨胀卷积的定义
depth_conv = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3,
                       groups=6, dilation=2)
point_conv = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=1)
depthwise_separable_conv = torch.nn.Sequential(depth_conv, point_conv)

class MnistNetword(nn.Module):
    def __init__(self):
        super(MnistNetword, self).__init__()
        self.convs_stack = nn.Sequential(
            nn.Conv2d(1,12,kernel_size=7),
            nn.ReLU(),
            depthwise_separable_conv,  #使用自定义卷积替代了原生卷积层
            nn.ReLU(),
            nn.Conv2d(24,6,kernel_size=3)
        )

        self.logits_layer = nn.Linear(in_features=1536,out_features=10)

    def forward(self,inputs):
        image = inputs
        x = self.convs_stack(image)
        x = elt.Rearrange("b c h w -> b (c h w)")(x)
        logits = self.logits_layer(x)
        return logits
```

可以看到，我们在中层部分使用自定义的卷积层替代了部分原生卷积层。完整的训练代码如下：

```python
import torch
import torch.nn as nn
import numpy as np
import einops.layers.torch as elt

#载入数据
x_train = np.load("../dataset/mnist/x_train.npy")
y_train_label = np.load("../dataset/mnist/y_train_label.npy")

x_train = np.expand_dims(x_train,axis=1)
print(x_train.shape)

depth_conv = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3,
                       groups=6, dilation=2)
point_conv = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=1)
# 深度、可分离、膨胀卷积的定义
depthwise_separable_conv = torch.nn.Sequential(depth_conv, point_conv)

class MnistNetword(nn.Module):
    def __init__(self):
        super(MnistNetword, self).__init__()
        self.convs_stack = nn.Sequential(
            nn.Conv2d(1,12,kernel_size=7),
            nn.ReLU(),
            depthwise_separable_conv,
            nn.ReLU(),
            nn.Conv2d(24,6,kernel_size=3)
        )

        self.logits_layer = nn.Linear(in_features=1536,out_features=10)

    def forward(self,inputs):
        image = inputs
        x = self.convs_stack(image)
        x = elt.Rearrange("b c h w -> b (c h w)")(x)
        logits = self.logits_layer(x)
        return logits

device = "cuda" if torch.cuda.is_available() else "cpu"
#注意需要将model发送到GPU计算
model = MnistNetword().to(device)
model = torch.compile(model)
loss_fn = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)

batch_size = 128
for epoch in range(63):
    train_num = len(x_train)//128
    train_loss = 0.
    for i in range(train_num):
        start = i * batch_size
        end = (i + 1) * batch_size

        x_batch = torch.tensor(x_train[start:end]).to(device)
        y_batch = torch.tensor(y_train_label[start:end]).to(device)

        pred = model(x_batch)
        loss = loss_fn(pred, y_batch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()  # 记录每个批次的损失值

    # 计算并打印损失值
    train_loss /= train_num
    accuracy = (pred.argmax(1) == y_batch).type(torch.float32).sum().item() / batch_size
    print("epoch:",epoch,"train_loss:",
          round(train_loss,2),"accuracy:",round(accuracy,2))
```
最终计算结果请读者自行完成。

### 5.4 本章小结

本章是PyTorch 2.0中一个非常重要的部分，也对后期常用的API进行了使用介绍，主要介绍了使用卷积对MNIST数据集进行识别。这是一个入门案例，但是包含的内容非常多，例如使用多种不同的层和类构建一个较为复杂的卷积神经网络。本章也向读者介绍了一些新的具有个性化设置的卷积层。

除此之外，本章通过演示自定义层的方法向读者说明了一个新的编程范式的使用，通过block的形式对模型进行组合，这在后期有一个专门的名称“残差卷积”。这是一种非常优雅的模型设计模式。

本章内容非常重要，希望读者认真学习。 
