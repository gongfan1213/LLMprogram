#### 7.1.4 ResNet网络的实现
在介绍完ResNet模块的实现后，下面使用完成的ResNet Block模型实现完整的ResNet。ResNet的结构如图7-8所示。

![image](https://github.com/user-attachments/assets/8c211c3b-1116-41e8-a37e-973a8ebb3c97)


**图7-8 ResNet的结构**

图7-8一共给出了5种深度的ResNet，分别是18、34、50、101和152，其中所有的网络都分成5部分，分别是conv1、conv2_x、conv3_x、conv4_x和conv5_x。

说明：ResNet完整的实现需要较高性能的显卡，因此我们对其做了修改，去掉了Pooling层，并降低了每次filter的数目和每层的层数，这一点请读者注意。

完整实现ResNet模型的结构如下：

```python
import torch
import torch.nn as nn

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        #residual function
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * BasicBlock.expansion)
        )

        #shortcut
        self.shortcut = nn.Sequential()

        #判定输出的维度是否和输入相一致
        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * BasicBlock.expansion)
            )

    def forward(self, x):
        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))


class ResNet(nn.Module):
    def __init__(self, block, num_block, num_classes=100):
        super().__init__()
        self.in_channels = 64
        self.conv = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )
        #在这里我们使用构造函数的形式，根据传入的模型结构进行构建，读者直接记住这种写法即可
        self.conv2_x = self.make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self.make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self.make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self.make_layer(block, 512, num_block[3], 2)
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

    def make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion

        return nn.Sequential(*layers)

    def forward(self, x):
        output = self.conv(x)
        output = self.conv2_x(output)
        output = self.conv3_x(output)
        output = self.conv4_x(output)
        output = self.conv5_x(output)
        output = self.avg_pool(output)
        #首先使用view作为全局池化层，fc是最终的分类函数，为每层对应的类别进行分类计算
        output = output.view(output.size(0), -1)
        output = self.fc(output)

        return output


#18层的ResNet
def resnet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])

#34层的ResNet
def resnet34():
    return ResNet(BasicBlock, [3, 4, 6, 3])

if __name__ == '__main__':
    image = torch.randn(size=(5,3,224,224))
    resnet = ResNet(BasicBlock, [2, 2, 2, 2])

    img_out = resnet(image)
    print(img_out.shape)
```

在这里需要提醒的是，根据输入层数的不同，作者采用PyTorch 2.0中特有的构造方法对传入的块形式进行构建，使用view层作为全局池化层，之后的fc层对结果进行最终的分类。请读者注意，这里为了配合7.2节的CIFAR-10数据集分类，分类结果被设置成10种。

为了演示，在这里实现了18层和34层的ResNet模型的构建，更多的模型请读者自行完成。

### 7.2 ResNet实战：CIFAR-10数据集分类
本节将使用ResNet实现CIFAR-10数据集分类。

#### 7.2.1 CIFAR-10数据集简介
CIFAR-10数据集共有60000幅彩色图像，这些图像是32×32像素的，分为10个类，每类6000幅图。这里面有50000幅用于训练，构成了5个训练批，每一批10000幅图；另外10000幅图用于测试，单独构成一批。测试批的数据取自100类中的每一类，每一类随机取1000幅图。抽剩下的就随机排列组成训练批。注意，一个训练批中的各类图像的数量并不一定相同，总的来看，训练批每一类都有5000幅图，如图7-9所示。



**图7-9 CIFAR-10数据集**

读者自行搜索CIFAR-10数据集下载地址，进入下载页面后，选择下载方式，如图7-10所示。

**图7-10 下载方式**

由于PyTorch 2.0采用Python语言编程，因此选择python version版本下载。下载之后解压缩，得到如图7-11所示的几个文件。



**图7-11 得到的文件**

data_batch_1 ~ data_batch_5是划分好的训练数据，每个文件中包含10000幅图片，test_batch是测试集数据，也包含10000幅图片。

读取数据的代码如下：

```python
import pickle
def load_file(filename):
    with open(filename, 'rb') as fo:
        data = pickle.load(fo, encoding='latin1')
    return data
```

首先定义读取数据的函数，这几个文件都是通过pickle产生的，所以在读取的时候也要用到这个包。返回的data是一个字典，先来看这个字典里面有哪些键。

```python
data = load_file('data_batch_1')
print(data.keys())
```

输出结果如下：

```python
dict_keys(['batch_label', 'labels', 'data', 'filenames'])
```

具体说明如下：
- batch_label：对应的值是一个字符串，用来表明当前文件的一些基本信息。
- labels：对应的值是一个长度为10000的列表，每个数字取值范围为0~9，代表当前图片所属的类别。 
- data：10000×3072的二维数组，每一行代表一幅图片的像素值。 
- filenames：长度为10000的列表，里面每一项是代表图片文件名的字符串。

完整的数据读取函数如下。

```python
import pickle
import numpy as np
import os

def get_cifar10_train_data_and_label(root=""):
    def load_file(filename):
        with open(filename, 'rb') as fo:
            data = pickle.load(fo, encoding='latin1')
        return data

    data_batch_1 = load_file(os.path.join(root, 'data_batch_1'))
    data_batch_2 = load_file(os.path.join(root, 'data_batch_2'))
    data_batch_3 = load_file(os.path.join(root, 'data_batch_3'))
    data_batch_4 = load_file(os.path.join(root, 'data_batch_4'))
    data_batch_5 = load_file(os.path.join(root, 'data_batch_5'))
    dataset = []
    labelset = []
    for data in [data_batch_1, data_batch_2, data_batch_3, data_batch_4, data_batch_5]:
        img_data = (data["data"])
        img_label = (data["labels"])
        dataset.append(img_data)
        labelset.append(img_label)
    dataset = np.concatenate(dataset)
    labelset = np.concatenate(labelset)
    return dataset, labelset

def get_cifar10_test_data_and_label(root=""):
    def load_file(filename):
        with open(filename, 'rb') as fo:
            data = pickle.load(fo, encoding='latin1')
        return data
    data_batch_1 = load_file(os.path.join(root, 'test_batch'))
    dataset = []
    labelset = []
    for data in [data_batch_1]:
        img_data = (data["data"])
        img_label = (data["labels"])
        dataset.append(img_data)
        labelset.append(img_label)
    dataset = np.concatenate(dataset)
    labelset = np.concatenate(labelset)
    return dataset, labelset

def get_CIFAR10_dataset(root=""):
    train_dataset, label_dataset = get_cifar10_train_data_and_label(root=root)
    test_dataset, test_label_dataset = get_cifar10_train_data_and_label(root=root)
    return train_dataset, label_dataset, test_dataset, test_label_dataset

if __name__ == "__main__":
    train_dataset, label_dataset, test_dataset, test_label_dataset = get_CIFAR10_dataset(root="../dataset/cifar-10-batches-py/")

    train_dataset = np.reshape(train_dataset,[len(train_dataset),3,32,32]).astype(np.float32)/255.
    test_dataset = np.reshape(test_dataset,[len(test_dataset),3,32,32]).astype(np.float32)/255.
    label_dataset = np.array(label_dataset)
    test_label_dataset = np.array(test_label_dataset)
```

其中的root参数是下载数据解压后的目录，os.join函数将其组合成数据文件的位置。最终返回训练文件、测试文件以及它们对应的label。由于我们提取出的文件数据格式为[−1,3072]，因此需要重新对数据维度进行调整，使之适用模型的输入。

#### 7.2.2 基于ResNet的CIFAR-10数据集分类
前面章节中，我们对ResNet模型以及CIFAR-10数据集做了介绍，本小节将使用前面定义的ResNet模型进行分类任务。

在7.2.1节中已经介绍了CIFAR-10数据集的基本构成，并讲解了ResNet的基本模型结构，接下来直接导入对应的数据和模型即可。完整的模型训练如下：

```python
import torch
import resnet
import get_data
import numpy as np

train_dataset, label_dataset, test_dataset, test_label_dataset = get_data.get_CIFAR10_dataset(root="../dataset/cifar-10-batches-py/")

train_dataset = np.reshape(train_dataset,[len(train_dataset),3,32,32]).astype(np.float32)/255.
test_dataset = np.reshape(test_dataset,[len(test_dataset),3,32,32]).astype(np.float32)/255.
label_dataset = np.array(label_dataset)
test_label_dataset = np.array(test_label_dataset)

device = "cuda" if torch.cuda.is_available() else "cpu"
model = resnet.resnet18()  #导入ResNet模型
model = model.to(device)  #将计算模型传入GPU硬件等待计算
model = torch.compile(model)  #PyTorch 2.0的特性，加速计算速度
optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)  #设定优化函数
loss_fn = torch.nn.CrossEntropyLoss()

batch_size = 128
train_num = len(label_dataset)//batch_size
for epoch in range(63):

    train_loss = 0.
    for i in range(train_num):
        start = i * batch_size
        end = (i + 1) * batch_size

        x_batch = torch.from_numpy(train_dataset[start:end]).to(device)
        y_batch = torch.from_numpy(label_dataset[start:end]).to(device)

        pred = model(x_batch)
        loss = loss_fn(pred, y_batch.long())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()  # 记录每个批次的损失值

    # 计算并打印损失值
    train_loss /= train_num
    accuracy = (pred.argmax(1) == y_batch).type(torch.float32).sum().item() / batch_size

    #2048可根据读者cpu显存大小调整
    test_num = 2048
    x_test = torch.from_numpy(test_dataset[:test_num]).to(device)
    y_test = torch.from_numpy(test_label_dataset[:test_num]).to(device)
    pred = model(x_test)
    test_accuracy = (pred.argmax(1) == y_test).type(torch.float32).sum().item() / test_num
    print("epoch:",epoch,"train_loss:",
          round(train_loss,2),";accuracy:",round(accuracy,2),";test_accuracy:",round(test_accuracy,2))
```

在这里使用训练集数据对模型进行训练，之后使用测试集数据对其输出进行测试，训练结果如图7-12所示。

**图7-12 训练结果**

```
epoch: 0 train_loss: 1.83 ;accuracy: 0.6 ;test_accuracy: 0.56
epoch: 1 train_loss: 1.3 ;accuracy: 0.64 ;test_accuracy: 0.66
epoch: 2 train_loss: 0.83 ;accuracy: 0.76 ;test_accuracy: 0.79
epoch: 3 train_loss: 0.42 ;accuracy: 0.91 ;test_accuracy: 0.9
epoch: 4 train_loss: 0.23 ;accuracy: 0.99 ;test_accuracy: 0.95
epoch: 5 train_loss: 0.11 ;accuracy: 0.99 ;test_accuracy: 0.98
```



可以看到，经过5轮后，模型在训练集的准确率达到0.99，在测试集的准确率也达到0.98，这是一个较好的成绩，可以看到模型的性能达到较高水平。

其他层次的模型请读者自行尝试，根据读者自己不同的硬件设备，模型的参数和训练集的batch_size都需要作出调整，具体数值请根据需要对它们进行设置。

### 7.3 本章小结
本章是一个起点，让读者站在巨人的肩膀上，从冠军开始！

ResNet通过“直连”和“模块”的方法开创了一个AI时代，改变了人们仅依靠堆积神经网络层来获取更高性能的做法，在一定程度上解决了梯度消失和梯度爆炸的问题。这是一项跨时代的发明。

当简单的堆积神经网络层的做法失效的时候，人们开始采用模块化的思想设计网络，同时在不断“加宽”模块的内部通道。但是，当这些能够使用的方法被挖掘穷尽后，有没有新的方法能够进一步提升卷积神经网络的效果呢？

答案是有的。对于深度学习来说，除了对模型的精巧设计以外，还要对损失函数和优化函数进行修正，甚至随着对深度学习的研究，科研人员对深度学习有了进一步的了解，新的模型结构也被提出，这在后面的章节中也会讲解。 
