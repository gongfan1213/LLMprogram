### 第2章 PyTorch 2.0深度学习环境搭建
工欲善其事，必先利其器。第1章介绍了人工智能、大模型以及PyTorch 2.0之间的关系，本章开始正式进入PyTorch 2.0的讲解与教学中。

首先读者需要知道的是，无论是构建深度学习应用程序还是应用已完成训练的项目到某项具体项目中，都需要使用编程语言完成设计者的目的，在本书中使用Python语言作为开发的基本语言。

Python是深度学习的首选开发语言，很多第三方提供了集成大量科学计算类库的Python标准安装包，常用的是Miniconda和Anaconda。Python是一个脚本语言，如果不使用Miniconda或者Anaconda，那么第三方库的安装会比较困难，导致各个库之间的依赖关系变得复杂，从而导致安装和使用问题。因此，这里推荐安装Miniconda来替代原生Python语言的安装。

本章将首先介绍Miniconda的完整安装，之后完成一个练习项目，生成可控手写体数字，这是一个入门程序，帮助读者了解完整的PyTorch项目的工作过程。

#### 2.1 环境搭建1：安装Python
##### 2.1.1 Miniconda的下载与安装

1. **下载和安装**

打开Miniconda官方网站，其下载页面如图2-1所示。

读者可以根据自己的操作系统选择不同平台的Miniconda下载，目前提供的是新集成了Python 3.10版本的Miniconda。如果读者使用的是以前的Python版本，例如Python 3.9，也是完全可以的，笔者经过测试，无论是3.10版本还是3.9版本的Python，都不影响PyTorch的使用。

![image](https://github.com/user-attachments/assets/d1ff7e2e-6fc2-4b09-a406-754485e732d3)


（1）这里推荐使用Windows Python 3.9版本，相对于3.10版本，3.9版本经过一段时间的训练具有一定的稳定性。当然，读者可根据自己的喜好选择。集成Python 3.9版本的Miniconda可以在官方网站下载，打开后如图2-2所示。注意：如果读者使用的是64位操作系统，那么可以选择以Miniconda3开头、以64结尾的安装文件，不要下载错了。

![image](https://github.com/user-attachments/assets/9e356ca2-ef56-487c-a762-b8888a79d806)


（2）下载完成后得到的文件是.exe版本，直接运行即可进入安装过程。安装完成后，出现如图2-3所示的目录结构，说明安装正确。

![image](https://github.com/user-attachments/assets/de07726d-9ed6-4a8d-bd90-5e0ab9a0fbb1)


2. **打开控制台**
之后依次单击“开始”→“所有程序”→Miniconda3→Miniconda Prompt，打开Miniconda Prompt窗口，它与CMD控制台类似，输入命令就可以控制和配置Python。在Miniconda中常用的是conda命令，该命令可以执行一些基本操作。

3. **验证Python**
接下来，在控制台中输入python，如果安装正确，就会打印出版本号和控制符号。在控制符号下输入代码：
```python
print("hello")
```
结果如图2-4所示。

![image](https://github.com/user-attachments/assets/4c6bf1ef-8fc1-4343-a798-2dc167855c15)


4. **使用pip命令**

使用Miniconda的好处在于，它能够很方便地帮助读者安装和使用大量第三方类库。查看已安装的第三方类库的代码如下：
```python
pip list
```
注意：如果此时CMD控制台命令行还在>>>状态，可以输入exit()退出。

在Miniconda Prompt控制台输入pip list命令，结果如图2-5所示（局部截图）。

![image](https://github.com/user-attachments/assets/e42a67ee-e0ca-49aa-ad81-7ba146589a4e)


Miniconda中使用pip进行操作的方法还有很多，其中最重要的是安装第三方类库，命令如下：
```python
pip install name
```
这里的name是需要安装的第三方类库名，假设需要安装NumPy包（这个包已经安装过），那么输入的命令如下：
```python
pip install numpy
```
结果如图2-6所示。

使用Miniconda的一个好处是默认安装了大部分学习所需的第三方类库，这样能够避免使用者在安装和使用某个特定的类库时出现依赖类库缺失的情况。

![image](https://github.com/user-attachments/assets/09d34705-25da-4003-842c-cb1c6d83c9c9)


##### 2.1.2 PyCharm的下载与安装
和其他语言类似，Python程序的编写可以使用Windows自带的控制台进行编写。但是这种方式对于较为复杂的程序工程来说，容易混淆相互之间的层级和交互文件，因此在编写程序工程时，建议使用专用的Python编译器PyCharm。

1. **PyCharm的下载和安装**
（1）进入PyCharm官网的Download页面后，可以找到Other versions链接并打开，在这个页面上根据自己的系统选择免费的社区版（Community Edition）下载，如图2-7所示。

![image](https://github.com/user-attachments/assets/d5f56a4f-cc00-43cf-b720-e0f99745d078)


（2）下载安装文件后双击运行进入PyCharm安装界面，如图2-8所示。单击Next按钮继续安装即可。

（3）如图2-9所示，在配置界面上勾选所有的复选框，这些配置方便我们使用PyCharm。

![image](https://github.com/user-attachments/assets/8c40f14e-defe-4cd5-b682-42ae360a99e3)


（4）安装完成后，单击Finish按钮，如图2-10所示。

![image](https://github.com/user-attachments/assets/9e9ae9b8-613f-43f0-959b-ca5fc49d7ebb)


2. **使用PyCharm创建程序**

（1）单击桌面上新生成的 图标进入PyCharm程序界面，首先是第一次启动的定位，如图2-11所示。这里是对程序存储的定位，建议选择第2个Do not import settings。

（2）单击OK按钮后进入PyCharm配置界面，如图2-12所示。

![image](https://github.com/user-attachments/assets/b0f7a8f9-959e-4ec4-9593-494d2bf58e3a)

![image](https://github.com/user-attachments/assets/314c12f2-a6cc-4bcd-8806-e7d65adc6290)


（3）在配置界面可以对PyCharm的界面进行配置，选择自己的使用风格。如果对其不熟悉，直接使用默认配置也可以。如图2-13所示，我们把界面背景设置为白色。

![image](https://github.com/user-attachments/assets/5d660af8-30cb-4266-ab18-f4a4f773f1b3)


（4）创建一个新的工程，如图2-14所示。读者可以尝试把本书配套源码创建为新工程。

![image](https://github.com/user-attachments/assets/976b3630-8b77-47a1-ab98-564080090732)


这里尝试在工程中新建一个Python文件，如图2-15所示。在工程目录下，右击打开菜单，选择New→Python File，新建一个helloworld.py文件，打开一个编辑页并输入代码，如图2-16所示。

单击菜单栏中的Run→run…运行代码，或者右击helloworld.py文件名，在弹出的快捷菜单中选择run。如果成功输出hello world，那么恭喜你，Python与PyCharm的配置就完成了。

![image](https://github.com/user-attachments/assets/4e6f1cb8-005d-44b9-9861-1833348f3273)


##### 2.1.3 Python代码小练习：计算Softmax函数
对于Python科学计算来说，最简单的想法就是可以将数学公式直接表达成程序语言，可以说，Python满足了这个想法。本小节将使用Python实现和计算一个深度学习中最为常见的函数——Softmax函数。至于这个函数的作用，现在不加以说明，笔者只是带领读者尝试实现其程序的编写。

![image](https://github.com/user-attachments/assets/38e2f4f7-78ae-4f65-b1a0-f43faf649509)


Softmax函数的计算公式如下：
\[ S_{i}=\frac{e^{V_{i}}}{\sum_{j = 0}^{}e^{V_{j}}} \]

其中\( V_{i} \)是长度为\( j \)的数列\( V \)中的一个数，代入Softmax的结果就是先对每一个\( V_{i} \)取以\( e \)为底的指数计算变成非负，然后除以所有项之和进行归一化，之后每个\( V_{i} \)就可以解释成：在观察到的数据集类别中，特定的\( V_{i} \)属于某个类别的概率，或者称作似然（Likelihood）。

提示：Softmax用以解决概率计算中概率结果大而占绝对优势的问题。例如函数计算结果中的2个值\( a \)和\( b \)，且\( a>b \)，如果简单地以值的大小为单位衡量的话，那么在后续的使用过程中，\( a \)永远被选用，而\( b \)由于数值较小不会被选择，但是有时也需要使用数值较小的\( b \)，Softmax就可以解决这个问题。

Softmax按照概率选择\( a \)和\( b \)，由于\( a \)的概率值大于\( b \)，因此在计算时\( a \)经常会被取得，而\( b \)由于概率较小，取得的可能性也较小，但是也有概率被取得。

Softmax公式的代码如下：
```python
import numpy
def softmax(inMatrix):
    m,n = numpy.shape(inMatrix)
    outMatrix = numpy.mat(numpy.zeros((m,n)))
    soft_sum = 0
    for idx in range(0,n):
        outMatrix[0,idx] = math.exp(inMatrix[0,idx])
        soft_sum += outMatrix[0,idx]
    for idx in range(0,n):
        outMatrix[0,idx] = outMatrix[0,idx] / soft_sum
    return outMatrix
```
可以看到，当传入一个数列后，分别计算每个数值所对应的指数函数值，将其相加后计算每个数值在数值和中的概率。

```python
a = numpy.array([[1,2,1,2,1,1,3]])
```
结果请读者自行打印验证。

#### 2.2 环境搭建2：安装PyTorch 2.0
Python运行环境调试完毕后，本节重点介绍安装本书的主角——PyTorch 2.0。

##### 2.2.1 Nvidia 10/20/30/40系列显卡选择的GPU版本
由于40系显卡的推出，目前市场上会同时有Nvidia10/20/30/40系列显卡并存的情况。对于需要调用专用编译器的PyTorch来说，不同的显卡需要安装不同的依赖计算包，作者在此总结了不同显卡的PyTorch版本以及CUDA和cuDNN的对应关系，如表2-1所示。

|显卡型号|PyTorch GPU版本|CUDA版本|cuDNN版本|
| ---- | ---- | ---- | ---- |
|10系列及以前|PyTorch 2.0以前的版本|11.1|7.65|
|20/30/40系列|PyTorch 2.0向下兼容|11.6+|8.1+|

注意：这里主要是显卡运算库CUDA与cuDNN的区别，当在20/30/40系列显卡上使用PyTorch时，可以安装11.6版本以上以及cuDNN 8.1版本以上的包，而在10系列版本的显卡上，建议优先使用2.0版本以前的PyTorch。

下面以CUDA 11.7+cuDNN 8.2.0组合为例，演示完整的PyTorch 2.0 GPU Nvidia运行库的安装步骤，其他不同版本CUDA+cuDNN组合的安装过程基本一致。

##### 2.2.2 PyTorch 2.0 GPU Nvidia运行库的安装
从CPU版本的PyTorch开始深度学习之旅完全是可以的，但却不是笔者推荐的。相对于GPU版本的PyTorch来说，CPU版本的运行速度存在着极大的劣势，很有可能会让读者的深度学习止步于前。

PyTorch 2.0 CPU版本的安装命令如下：
```python
pip install numpy --pre torch torchvision torchaudio --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cpu
```

如果读者的计算机支持GPU，则继续下面本小节的重头戏，PyTorch 2.0 GPU版本的前置软件的安装。对于GPU版本的PyTorch来说，由于调用了NVIDIA显卡作为其代码运行的主要工具，因此额外需要NVIDIA提供的运行库作为运行基础。

对于PyTorch 2.0的安装来说，最好根据官方提供的安装命令进行安装，如图2-17所示。在这里PyTorch官方提供了两种安装模式，分别对应CUDA 11.7与CUDA 11.8。

![image](https://github.com/user-attachments/assets/4acb942b-d3ce-483e-9516-66f62a5b1e32)


从图中可以看到，这里提供了两种不同的CUDA版本的安装，作者经过测试，无论是使用CUDA 11.7还是CUDA 11.8，在PyTorch 2.0的程序编写上没有显著的区别，因此读者可以根据安装配置自行选择。下面以CUDA 11.7+cuDNN 8.2.0为例讲解它们的安装方法。

（1）安装CUDA。在百度搜索CUDA 11.7，进入官方下载页面，选择合适的操作系统安装方式（推荐使用exe（local）本地化安装方式），如图2-18所示。

![image](https://github.com/user-attachments/assets/ea0f62c1-7f4a-443b-8019-23f0a23a710f)


此时下载的是一个.exe文件，读者自行安装时，不要修改其中的路径信息，直接使用默认路径安装即可。

（2）下载和安装对应的cuDNN文件。cuDNN的下载需要先注册一个用户，相信读者可以很快完成，之后直接进入下载页面，如图2-19所示。注意：不要选择错误的版本，一定要找到对应的版本号。另外，如果使用的是Windows 64位的操作系统，那么直接下载x86版本的cuDNN即可。

![image](https://github.com/user-attachments/assets/2c2981b6-2675-491a-b6c0-c2e22cbde3a8)


下载的cuDNN 8.2.0是一个压缩文件，将其解压到CUDA安装目录，如图2-20所示。

![image](https://github.com/user-attachments/assets/709c1604-a8d4-46d5-bcd1-5f6c8f9a08e8)


（3）配置环境变量，这里需要将CUDA的运行路径加到环境变量Path的值中，如图2-21所示。如果cuDNN是使用.exe文件安装的，那这个环境变量自动就配置好了，读者只要验证一下即可。

![image](https://github.com/user-attachments/assets/d783ce88-1dfd-4ffd-9a8a-bf0c8c7a32a2)


（4）安装PyTorch及相关软件。从图2-17可以看到，对应CUDA 11.7的安装命令如下：
```python
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```

安装完成后，为了验证PyTorch是否安装成功，可以打开Miniconda Prompt，输入以下代码：
```python
import torch
print(torch.__version__)
print(torch.cuda.is_available())
```
如果输出PyTorch的版本号，并且cuda.is_available()输出True，说明PyTorch 2.0 GPU版本安装成功。

##### 2.2.3 PyTorch 2.0小练习：Hello PyTorch
安装完PyTorch 2.0后，我们通过一个简单的小练习来感受一下PyTorch的使用。在PyCharm中新建一个Python文件，命名为hello_pytorch.py，输入以下代码：
```python
import torch

# 创建一个张量
x = torch.tensor([1, 2, 3])
print(x)
```
运行这段代码，如果能够正确输出张量\( x \)的值，就说明我们已经能够在程序中正常使用PyTorch了。这只是一个非常简单的开始，后续我们将利用PyTorch进行更复杂的深度学习任务。

#### 2.3 生成式模型实战：古诗词的生成
在完成了PyTorch 2.0的环境搭建后，我们可以开始尝试一些简单的实战项目。本节将介绍如何使用PyTorch构建一个简单的生成式模型来进行古诗词的生成。

生成式模型是一种能够学习数据分布并生成新数据的模型。在古诗词生成中，我们希望模型能够学习古诗词的语言模式和规律，从而生成符合逻辑和韵律的新古诗词。

首先，我们需要准备古诗词的数据集。可以从网络上收集大量的古诗词文本，然后对这些文本进行预处理，例如将文本转换为数字编码，以便模型能够处理。

接下来，我们可以构建一个基于循环神经网络（RNN）或者长短期记忆网络（LSTM）的模型结构。这些网络结构能够很好地处理序列数据，适合用于语言生成任务。

在构建好模型后，我们需要定义损失函数和优化器。损失函数用于衡量模型生成的结果与真实古诗词之间的差异，优化器则用于更新模型的参数，以最小化损失函数的值。

最后，通过训练模型，不断调整模型的参数，使其能够更好地学习古诗词的模式。当模型训练完成后，我们就可以输入一个起始的词语或者句子，让模型生成后续的古诗词内容。

下面是一个简单的代码框架示例：
```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# 假设已经完成了数据集的准备和预处理
# 定义数据集类
class PoemDataset(Dataset):
    def __init__(self, data):
        self.data = data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

# 定义模型
class PoemGenerator(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(PoemGenerator, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x, hidden):
        out, hidden = self.lstm(x, hidden)
        out = self.fc(out[:, -1, :])
        return out, hidden

    def init_hidden(self, batch_size):
        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),
                torch.zeros(self.num_layers, batch_size, self.hidden_size))

# 定义训练过程
def train(model, dataloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    for i, data in enumerate(dataloader, 0):
        inputs = data.to(device)
        hidden = model.init_hidden(inputs.size(0))
        optimizer.zero_grad()
        outputs, _ = model(inputs, hidden)
        loss = criterion(outputs, inputs[:, 1:])
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
