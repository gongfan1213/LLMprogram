
### 第5章 基于PyTorch卷积层的MNIST分类实战

第3章使用多层感知机完成了MNIST分类实战的演示。多层感知机是一种对目标数据进行整体分类的计算方法。虽然从演示效果来看，多层感知机可以较好地完成项目标对数据进行完整分类，但是多层感知机会在模型中使用大规模的参数，同时，由于是对数据进行总体性的处理，从而无可避免地会忽略数据局部特征的处理和掌握，因此我们需要一种新的能够对输入数据的局部特征进行抽取和计算的工具。

卷积神经网络是从信号处理衍生过来的一种对数字信号进行处理的方式，发展到图像信号处理上演变成一种专门用来处理具有矩阵特征的网络结构处理方式。卷积神经网络在很多应用上都有独特的优势，甚至可以说是无可比拟的，例如音频的处理和图像处理。

本章将会介绍卷积神经网络的基本概念。首先，我们将阐述卷积实际上是一种不太复杂的数学运算，它是一种特殊的线性运算形式。接下来，将详细解释“池化”这一概念，这是卷积神经网络中必不可少的操作。最后，我们将探讨为了消除过拟合而采用的drop - out这个常用的方法。这些概念和方法都是为了让卷积神经网络运行得更加高效和稳定。



#### 5.1 卷积运算的基本概念

在数字图像处理中有一种基本的处理方法，即线性滤波。它将待处理的二维数字看作一个大型矩阵，图像中的每个像素可以看作矩阵中的每个元素，像素的大小就是矩阵中的元素值。

而使用的滤波工具是另一个小型矩阵，这个矩阵被称为卷积核。卷积核的大小远小于图像矩阵，而具体的计算方式就是计算图像大矩阵中的每个像素周围的像素和卷积核对应位置的乘积，之后将结果相加，最终得到的值就是该像素的值，这样就完成了一次卷积。简单的图像卷积方式如图5 - 1所示。

![image](https://github.com/user-attachments/assets/3910659f-90f2-411e-b0f0-5801d82e4970)


本节将详细介绍卷积的运算和定义，以及一些细节调整，这些都是使用卷积的过程中必不可少的内容。



##### 5.1.1 基本卷积运算示例

前面已经讲过了，卷积实际上是使用两个大小不同的矩阵进行的一种数学运算。为了便于读者理解，我们从一个例子开始介绍。

对高速公路上的跑车的位置进行追踪，这是卷积神经网络图像处理中的一个非常重要的应用。摄像头接收到的信号被计算为x(t)，表示跑车在路上时刻t的位置。

但是实际上的处理往往没那么简单，因为在自然界无时无刻不面临各种影响以及摄像头传感器的滞后。为了得到跑车位置的实时数据，采用的方法就是对测量结果进行均值化处理。对于运动中的目标，采样时间越长，由于滞后性的原因，定位的准确率越低，而采样时间越短，则可以认为越接近真实值。因此，可以对不同的时间段赋予不同的权重，即通过一个权值定义来计算，可以表示为：

\[ s(t)=\int x(a)\omega(t - a)da \]

这种运算方式被称为卷积运算。换个符号表示为：

\[ s(t)=(x\omega)(t) \]

在卷积公式中，第一个参数x被称为“输入数据”；第二个参数ω被称为“核函数”；s(t)是输出，即特征映射。

对于稀疏矩阵来说，卷积网络具有稀疏性，即卷积核的大小远小于输入数据矩阵的大小。例如，当输入一个图片信息时，数据的大小可能为上万的结构，但是使用的卷积核却只有几十，这样能够在计算后获取更少的参数特征，极大地减少了后续的计算量，如图5 - 2所示。

![image](https://github.com/user-attachments/assets/1a648539-2bee-4039-bceb-fd395f494233)

![image](https://github.com/user-attachments/assets/f22c99f4-b60f-4269-a93f-c2621955b769)


在传统的神经网络中，每个权重只对其连接的输入输出起作用，当其连接的输入输出元素结束后就不会再用到。而参数共享指的是在卷积神经网络中核的每个元素都被用在输入的每个位置上，在过程中只需学习一个参数集合，就能把这个参数应用到所有的图片元素中。

```python

import numpy as np

dateMat = np.ones((7,7))

kernel = np.array([[2,1,1],[3,0,1],[1,1,0]])



def convolve(dateMat,kernel):

    m,n = dateMat.shape

    km,kn = kernel.shape

    newMat = np.ones(((m - km + 1),(n - kn + 1)))

    tempMat = np.ones((km),(kn))

    for row in range(m - km + 1):

        for col in range(n - kn + 1):

            for m_k in range(km):

                for n_k in range(kn):

                    tempMat[m_k,n_k] = dateMat[(row + m_k),(col + n_k)] * kernel[m_k,n_k]

            newMat[row,col] = np.sum(tempMat)
    return newMat
```
上面由Python基础运算包实现了卷积操作，这里卷积核从左到右、从上到下进行卷积计算，最后返回新的矩阵。

##### 5.1.2 PyTorch中的卷积函数实现详解

前面通过Python实现了卷积的计算，PyTorch为了框架计算的迅捷，同样使用了专门的高级API函数Conv2d(Conv)作为卷积计算函数，如图5 - 3所示。

```python

import torch
image = torch.randn(size=(5,3,128,128))
conv2d = torch.nn.Conv2d(3,10,kernel_size=3,stride=1,padding=1)
image_new = conv2d(image)
print(image_new.shape)
```
![image](https://github.com/user-attachments/assets/09ea2ead-d3c6-473f-8f3b-5b61f251a42b)


这个函数是搭建卷积神经网络的核心函数之一，其说明如下：
```python
class Conv2d(_ConvNd):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: _size_2_t,
        stride: _size_2_t = 1,
        padding: Union[str, _size_2_t] = 0,
        dilation: _size_2_t = 1,
        groups: int = 1,
        bias: bool = True,
        padding_mode: str = 'zeros',  # TODO: refine this type
        device=None,
        dtype=None
    ) -> None:
        ...
```
Conv2d是PyTorch的卷积层自带的函数，其最重要的5个参数如下。
- in_channels：输入的卷积核数目。
- out_channels：输出的卷积核数目。
- kernel_size：卷积核大小，它要求是一个输入向量，具有[filter_height, filter_width]这样的维度，具体含义是[卷积核的高度，卷积核的宽度]，要求类型与参数input相同。
- strides：步进大小，卷积时在图形计算时移动的步长，默认为1；如果参数是stride=(2, 1)，2代表着高（h）进行步长为2，1代表着宽（w）进行步长为1。 
- padding：补全方式，int类型的量，只能是1和0其中之一，这个值决定了不同的卷积方式。

使用卷积计算的示例代码如下：
```python
import torch
image = torch.randn(size=(5,3,128,128))
#下面是定义的卷积层示例
"""

输入维度: 3

输出维度: 10

卷积核大小: 基本写法是[3,3],这里简略写法3代表卷积核的长和宽大小一致

步长: 2

补偿方式: 维度不变补偿

"""

conv2d = torch.nn.Conv2d(3,10,kernel_size=3,stride=1,padding=1)

image_new = conv2d(image)

print(image_new.shape)

```

上面的代码段展示了一个使用TensorFlow高级API进行卷积计算的例子，在这里随机生成了5个[3,128,128]大小的矩阵，之后使用1个大小为[3,3]的卷积核对其进行计算，打印结果如下：

torch.Size([5, 10, 128, 128])

可以看到，这是计算后生成的新图形，其大小根据设置没有变化，这是由于我们所使用的padding补偿方式将其按原有大小进行补偿。具体来说，这是由于卷积在工作时边缘被处理消失，因此生成的结果小于原有的图像。

但是，若需要生成的卷积结果和原输入矩阵的大小一致，则需要将参数padding的值设为1，此时表示图像边缘将由一圈0补齐，使得卷积后的图像大小和输入大小一致，示意如下：

```

000000000000

0 xxxxxxxxxx 0

0 xxxxxxxxxx 0

0 xxxxxxxxxx 0

000000000000

```

其中可以看到，这里x是图片的矩阵信息，而外面一圈是补齐的0，0在卷积处理时对最终结果没有任何影响。这里略微对其进行修改，更多的参数调整请读者自行调试查看。

下面我们修改一下卷积核stride，也就是步进的大小，代码如下：

```python

import torch

image = torch.randn(size=(5,3,128,128))

conv2d = torch.nn.Conv2d(3,10,kernel_size=3,stride=2,padding=1)

image_new = conv2d(image)

print(image_new.shape)

```

我们使用同样大小的输入数据修正了卷积层的步进距离，最终结果如下：

torch.Size([5, 10, 64, 64])

下面我们对这个情况进行总结，经过卷积计算后，图像的大小变化可由如下公式进行确定：

\[ N=(W - F + 2P) // S+1 \]

- 输入图片大小为\(W×W\)。

- Filter大小为\(F×F\)。

- 步长为\(S\)。

- padding的像素数为\(P\)，一般情况下\(P = 1\)或者\(0\)（参考PyTorch）。



此时，把上述数据代入公式可得（注意取模计算）：

\[ N=(128 - 3+2) // 2+1 \]

需要注意的是，在这里是使用模计算，因此\(127//2 = 63\)。

![image](https://github.com/user-attachments/assets/13999d17-b5e8-4c18-b835-2b659067a2ed)


##### 5.1.3 池化运算
在通过卷积获得了特征（Feature）之后，下一步希望利用这些特征进行分类。理论上讲，人 

### 5.1.3 池化运算
理论上，人们可以用所有提取到的特征来训练分类器，例如Softmax分类器推导，但这样做会面临计算量的挑战。因此，为了降低计算量，我们尝试利用神经网络的“参数共享”这一特性。

这意味着在一个图像区域有用的特征极有可能在另一个区域同样适用。因此，为了描述大的图像，一个很自然的想法就是对不同位置的特征进行聚合统计。

例如，特征提取可以计算图像在一个区域上的某个特定特征的平均值（或最大值） ，如图5 - 4所示。这些概要统计特征不仅具有低得多的维度（相比使用所有提取到的特征），同时还会改善结果（不容易过拟合）。这种聚合的操作就叫作池化（Pooling），有时也称为平均池化或者最大池化（取决于计算池化的方法）。

![image](https://github.com/user-attachments/assets/fce44b0d-a653-48a1-be4a-deebbf7944f1)


如果选择图像中的连续范围作为池化区域，并且只是池化相同（重复）的隐藏单元产生的特征，那么这些池化单元就具有平移不变性（Translation Invariant） 。这就意味着即使图像经历了一个小的平移，依然会产生相同的（池化的）特征。在很多任务（例如物体检测、声音识别）中，我们更希望得到具有平移不变性的特征，因为即使图像经过了平移，样例（图像）的标记仍然保持不变。

PyTorch 2.0中池化运算的函数示例：
```python
class AvgPool2d(_AvgPoolNd):
    def __init__(self, kernel_size: _size_2_t, stride: Optional[_size_2_t] = None, padding: _size_2_t = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None:
        ...
```

重要的参数如下：

- kernel_size：池化窗口的大小，默认大小一般是[2,2]。

- strides：和卷积类似，窗口在每个维度上滑动的步长，默认大小一般也是[2,2]。 

- padding：和卷积类似，可以取1或者0，返回一个Tensor，类型不变，shape仍然是[batch, channel, height, width]这种形式。 



池化的一个非常重要的作用就是能够帮助输入的数据表示近似不变性。对于平移不变性，指的是对输入的数据进行少量平移时，经过池化后的输出结果并不会发生改变。局部平移不变性是一个很有用的性质，尤其是当关心某个特征是否出现而不关心它出现的具体位置时。

例如，当判定一幅图像中是否包含人脸时，并不需要判定眼睛的位置，而是需要知道有一只眼睛出现在脸部的左侧，另一只出现在右侧就可以了。使用池化层的代码如下：

```python
import torch
image = torch.randn(size=(5,3,28,28))
pool = torch.nn.AvgPool2d(kernel_size=3,stride=2,padding=0)
image_pooled = pool(image)
print(image_pooled.shape)
```
除此之外，PyTorch 2.0中还提供了一种新的池化层——全局池化层，使用方法如下：
```python
import torch
image = torch.randn(size=(5,3,28,28))
image_pooled = torch.nn.AdaptiveAvgPool2d(1)(image)
print(image_pooled.shape)
```
AdaptiveAvgPool2d函数的作用是对输入的图形进行全局池化，也就是在每个channel上对图形整体进行归一化的池化计算，结果请读者自行打印验证。

### 5.1.4 Softmax激活函数 
Softmax函数在前面已经做过介绍，并且作者使用NumPy自定义实现了Softmax的功能和函数。Softmax是一个对概率进行计算的模型，因为在真实的计算模型系统中，对一个实物的判定并不是100%，而是只有一定的概率，并且在所有的结果标签上都可以求出一个概率。
\[ f(x)=\sum_{i}^{l} w_{ij}x_j + b \]
\[ Softmax = \frac{e^{x_{i}}}{\sum_{j}^{l} e^{x_{j}}} \]
\[ y = Softmax(f(x)) = Softmax(w_{ij}x_j + b) \]

![image](https://github.com/user-attachments/assets/7430970d-4dee-4bf0-842b-f170209994b1)


其中第一个公式是人为定义的训练模型，这里采用的是输入数据与权重的乘积和，并加上一个偏置\(b\)的方式。偏置\(b\)存在的意义是为了加上一定的噪声。

对于求出的\(f(x)=\sum_{i}^{l} w_{ij}x_j + b\)，Softmax的作用是将其转换成概率。换句话说，这里的Softmax可以被看作是一个激励函数，将计算的模型输出转换为在一定范围内的数值，并且在总体中这些数值的和为1，而每个单独的数据结果都有其特定的概率分布。

用更为正式的语言表述，那就是Softmax是模型函数定义的一种形式：把输入值当成幂指数求值，再正则化这些结果值。而这个幂运算表示，更大的概率计算结果对应更大的假设模型中的乘数值，反之，拥有更少的概率计算结果意味着在假设模型中拥有更小的乘数权重值。假设模型中的权值不可以是0或者负值。Softmax会正则化这些权重值，使它们的总和等于1，以此构造一个有效的概率分布。

对于最终的公式\(y = softmax(f(x)) = softmax(w_{ij}x_j + b)\)来说，可以将其认为是如图5 - 5所示的形式。

图5 - 5演示了Softmax的计算公式，这实际上就是输入的数据通过与权重乘积之后，对其进行Softmax计算得到的结果。将其用数学方法表示如图5 - 6所示。

将这个计算过程用矩阵的形式表示出来，即矩阵乘法和向量加法，这样有利于使用TensorFlow内置的数学公式进行计算，极大地提高了程序效率。

### 5.1.5 卷积神经网络的原理

![image](https://github.com/user-attachments/assets/ed1ce2e4-cb02-43eb-aed9-acf1bc7be19d)


前面介绍了卷积运算的基本原理和概念，从本质上来说，卷积神经网络就是将图像处理中的二维离散卷积运算和神经网络相结合。这种卷积运算可以用于自动提取特征，而卷积神经网络主要应用于二维图像的识别。下面将采用一个图示更加直观地介绍卷积神经网络的工作原理。

一个卷积神经网络如果包含一个输入层、一个卷积层和一个输出层，那么在真正使用的时候一般会使用多层卷积神经网络不断地提取特征，特征越抽象，越有利于识别（分类）。而且通常卷积神经网络包含池化层、全连接层，最后接输出层。

图5 - 7展示了一幅图片进行卷积神经网络处理的过程，主要包含以下4个步骤：

- 图像输入：获取输入的数据图像。

- 卷积：对图像特征进行提取。 

- Pooling层：用于缩小在卷积时获取的图像特征。 

- 全连接层：用于对图像进行分类。 

![image](https://github.com/user-attachments/assets/a2ce139d-602b-4b5f-827f-6d51afb02640)


这几个步骤依次进行，分别具有不同的作用。经过卷积层的图像被卷积核心提取后，获得分块的、同样大小的图片，如图5 - 8所示。

可以看到，经过卷积处理后的图像被分为若干个大小相同的、只具有局部特征的图片。图5 - 9表示对分解后的图片使用一个小型神经网络进行进一步的处理，即将二维矩阵转化成一维数组。


![image](https://github.com/user-attachments/assets/b9127b20-4da2-4667-bef2-5fb53f2a0527)


需要说明的是，在这个步骤，也就是对图片进行卷积化处理时，卷积算法对所有分解后的局部特征进行同样的计算，这个步骤称为“权值共享” 。这样做的依据如下：

- 对图像等数组数据来说，局部数组的值经常是高度相关的，可以形成容易被探测到的独特的局部特征。 

- 图像和其他信号的局部统计特征与其位置是不太相关的，如果特征图能在图片的一个部分出现，那么也能出现在其他任何地方。所以不同位置的单元共享同样的权重，并在数组的不同部分探测相同的模式。 

在数学上，这种由一个特征图执行的过滤操作是一个离散的卷积，卷积神经网络由此得名。

池化层的作用是对获取的图像特征进行缩减。从前面的例子中可以看到，使用[2,2]大小的矩阵来处理特征矩阵，使得原有的特征矩阵可以缩减到1/4大小，特征提取的池化效应如图5 - 10所示。

![image](https://github.com/user-attachments/assets/4b4b5e5c-5c92-4cc5-9ee8-f91786f00577)


经过池化处理后的矩阵作为下一层神经网络的输入，使用一个全连接层对输入的数据进行分类计算（见图5 - 11），从而计算出这个图像对应位置最大的概率类别。

![image](https://github.com/user-attachments/assets/a87840cd-e256-46c7-81be-838eb3a98cd7)


采用较为通俗的语言概括，卷积神经网络是一个层级递增的结构，也可以将其认为是一个人在读报纸，首先一字一句地读取，之后整段地理解，最后获得全文的表述。卷积神经网络也是从边缘、结构和位置等一起感知物体的形状。 
